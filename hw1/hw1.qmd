---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 26, 2024 @ 11:59PM
author: Ruidong Zhang and 206294444
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
editor: 
  markdown: 
    wrap: 72
---

Display machine information for reproducibility:

```{r}
#| eval: false
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We 
work with Git and GitHub. Efficient and abundant use of Git, e.g.,
frequent and well-documented commits, is an important criterion for
grading your homework.

1.  Apply for the [Student Developer
    Pack](https://education.github.com/pack) at GitHub using your UCLA
    email. You'll get GitHub Pro account for free (unlimited public and
    private repositories).

2.  Create a **private** repository `biostat-203b-2024-winter` and add
    `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `jonathanhori` and
    `jasenzhang1` for Lec 80) as your collaborators with write
    permission.

3.  Top directories of the repository should be `hw1`, `hw2`, ...
    Maintain two branches `main` and `develop`. The `develop` branch
    will be your main playground, the place where you develop solution
    (code) to homework problems and write up report. The `main` branch
    will be your presentation area. Submit your homework files (Quarto
    file `qmd`, `html` file converted by Quarto, all code and extra data
    sets to reproduce results) in the `main` branch.

4.  After each homework due date, course reader and instructor will
    check out your `main` branch for grading. Tag each of your homework
    submissions with tag names `hw1`, `hw2`, ... Tagging time will be
    used as your submission time. That means if you tag your `hw1`
    submission after deadline, penalty points will be deducted for late
    submission.

5.  After this course, you can make this repository public and use it to
    demonstrate your skill sets on job market.

GitHub repository link:https://github.com/ruidzzz00/biostat-203b-2024-winter

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data
v2.2](https://physionet.org/content/mimiciv/2.2/), a freely accessible
critical care database developed by the MIT Lab for Computational
Physiology. Follow the instructions at
<https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI
`Data or Specimens Only Research` course and (2) obtain the PhysioNet
credential for using the MIMIC-IV data. Display the verification links
to your completion report and completion certificate here. **You must
complete Q2 before working on the remaining questions.** (Hint: The CITI
training takes a few hours and the PhysioNet credentialing takes a
couple days; do not leave it to the last minute.)

![](./citiCompletionCertificate_12933208_60526556.pdf)
[Certificate](https://drive.google.com/file/d/1squQqmX_557ZCrIBqZz_69ovw7NYvuUb/view?usp=sharing)


## Q3. Linux Shell Commands

1.  Make the MIMIC v2.2 data available at location `~/mimic`.

```{bash}
#| eval: false
ls -l ~/mimic/
```

Refer to the documentation <https://physionet.org/content/mimiciv/2.2/>
for details of data files. Please, do **not** put these data files into
Git; they are big. Do **not** copy them into your directory. Do **not**
decompress the gz data files. These create unnecessary big files and are
not big-data-friendly practices. Read from the data folder `~/mimic`
directly in following exercises.

Use Bash commands to answer following questions.

2.  Display the contents in the folders `hosp` and `icu` using Bash
    command `ls -l`. Why are these data files distributed as `.csv.gz`
    files instead of `.csv` (comma separated values) files? Read the
    page <https://mimic.mit.edu/docs/iv/> to understand what's in each
    folder.

```{bash}
#| eval: false
ls -l ~/mimic/hosp
ls -l ~/mimic/icu
```

The use of .csv.gz (compressed CSV) files instead of uncompressed .csv
files is typically done to reduce file size. The ".gz" extension
indicates that the file has been compressed using gzip compression,
which is a widely used and efficient compression algorithm.

3.  Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and
    `zgrep` do. 
    
    zcat: Function: Zcat is used to concatenate and display
    compressed files. It is similar to the 'cat' command but is
    specifically designed to work with compressed files, particularly
    gzip-compressed files (with a ".gz" extension). Usage: zcat
    filename.gz 
    
    zless: Function: Zless allows you to view the contents
    of compressed files page by page. It is similar to the 'less'
    command but works with gzip-compressed files, allowing you to scroll
    through the contents in a compressed state. Usage: zless filename.gz
    
    zmore: Function: Zmore is similar to Zless but is used to page
    through the contents of compressed files one screen at a time. It is
    an older command and is not as commonly used as Zless or other pager
    commands. Usage: zmore filename.gz 
    
    zgrep: Function: Zgrep is used to
    search through compressed files for a specific pattern using regular
    expressions. It combines the functionality of 'grep' with the
    ability to work with gzip-compressed files. Usage: zgrep pattern
    filename.gz These commands are particularly useful when dealing with
    large compressed files, allowing users to view, search, and
    concatenate the contents without the need to manually decompress the
    files first.

4.  (Looping in Bash) What's the output of the following bash script?

```{bash}
#| eval: true
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  ls -l $datafile
done
```

Display the number of lines in each data file using a similar loop.
(Hint: combine linux commands `zcat <` and `wc -l`.)

```{bash}
#| eval: false
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  echo "Number of lines in $datafile:"
  zcat < "$datafile" | wc -l
done
```

The number of lines in each data file is as follows:
Number of lines in ~/mimic/hosp/admissions.csv.gz: 431232
Number of lines in ~/mimic/hosp/labevents.csv.gz: 118171368
Number of lines in ~/mimic/hosp/patients.csv.gz: 299713

5.  Display the first few lines of `admissions.csv.gz`. How many rows
    are in this data file? How many unique patients (identified by
    `subject_id`) are in this data file? Do they match the number of
    patients listed in the `patients.csv.gz` file? (Hint: combine Linux
    commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and
    so on.)

```{bash}
#| eval: false
# Display the first few lines of admissions.csv.gz
zcat < ~/mimic/hosp/admissions.csv.gz | head
```

```{bash}
#| eval: true
#rows in this data file: 431232
zcat < ~/mimic/hosp/admissions.csv.gz | wc -l
```
The number of rows in this data file is 431232.

```{bash}
#| eval: true
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F',' 'NR>1 {print $1}' | sort -u | wc -l
zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | cut -d',' -f1 | uniq | wc -l
zcat < ~/mimic/hosp/patients.csv.gz | tail -n +2 | cut -d',' -f1 | uniq | wc -l
```
The number of unique patients (identified by subject_id) in
admissions.csv.gz is 180733. 

The number of unique patients (identified
by subject_id) in patients.csv.gz is 299712. 

They are not match the
number of patients listed in the patients.csv.gz file.

6.  What are the possible values taken by each of the variable
    `admission_type`, `admission_location`, `insurance`, and
    `ethnicity`? Also report the count for each unique value of these
    variables. (Hint: combine Linux commands `zcat`, `head`/`tail`,
    `awk`, `uniq -c`, `wc`, and so on; skip the header line.)

```{bash}
#| eval: true
# admission_type
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F',' 'NR>1 {print $6}' | sort | uniq -c
```

```{bash}
#| eval: true
# admission_location
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F',' 'NR>1 {print $8}' | sort | uniq -c
```

```{bash}
#| eval: true
# insurance
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F',' 'NR>1 {print $10}' | sort | uniq -c
```

```{bash}
#| eval: true
# ethnicity(race)
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F',' 'NR>1 {print $13}' | sort | uniq -c
```

7.  *To compress, or not to compress. That's the question.* Let's focus
    on the big data file `labevents.csv.gz`. Compare compressed gz file
    size to the uncompressed file size. Compare the run times of
    `zcat < ~/mimic/labevents.csv.gz | wc -l` versus
    `wc -l labevents.csv`. Discuss the trade off between storage and
    speed for big data files. (Hint:
    `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large
    `labevents.csv` file after the exercise.)

```{bash}
#| eval: false
# run time for labevents.csv.gz
time zcat < ~/mimic/hosp/labevents.csv.gz | wc -l
gzip -dk < ~/mimic/hosp/labevents.csv.gz > ./labevents.csv
# Measure time for labevents.csv
time wc -l ~/mimic/hosp/labevents.csv
rm labevents.csv # delete the large labevents.csv file
```

trade-off discussion for Storage vs. Speed: Compressed files offer
significant storage savings but come at the cost of additional
processing time during decompression when accessing the data. Access
Speed: Uncompressed files are faster to access because there's no
decompression step required. However, they consume more disk space.

## Q4. Who's popular in Price and Prejudice

1.  You and your friend just have finished reading *Pride and Prejudice*
    by Jane Austen. Among the four main characters in the book,
    Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was
    the most mentioned. You, however, are certain it was Elizabeth.
    Obtain the full text of the novel from\
    <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to
    your local folder.

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```

Explain what `wget -nc` does. Do **not** put this text file
`pg42671.txt` in Git. Complete the following loop to tabulate the number
of times each of the four characters is mentioned using Linux commands.

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
for char in Elizabeth Jane Lydia Darcy
do
  echo "$char:"
  grep -o -i "$char" pg42671.txt | wc -l
done
```

Result: Elizabeth was the most mentioned character in the book, I was
right. The wget -nc command is used to download a file from a specified
URL, and the -nc ensures that the file is not downloaded if it already
exists locally.

2.  What's the difference between the following two commands?

```{bash}
#| eval: false
echo 'hello, world' > test1.txt
```

and

```{bash}
#| eval: false
echo 'hello, world' >> test2.txt
```

The difference between the two commands is that the first command will
overwrite the file if it already exists, while the second command will
append the text to the end of the file if it already exists.

3.  Using your favorite text editor (e.g., `vi`), type the following and
    save the file as `middle.sh`:
    
using vi here
```{bash eval=FALSE}
vi middle.sh
```

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` to make the file executable by the owner, and run

```{bash}
#| eval: false
chmod +x middle.sh
./middle.sh pg42671.txt 20 5
```

Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in
this shell script. Why do we need the first line of the shell script?

Explanation: The output is a part of the content of the file 
pg42671.txt to introduce the book's Editor, Release date and Language. 
The "\$1", "\$2", and "\$3" in this shell script are used
to represent the first, second, and third arguments passed to the
script, respectively. In this case, the first argument is the file name,
the second argument is the release date, and the third argument is the
language. we need the first line of the shell script to indicate the
shell that will be used to run the script.

## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`,
`cal 2024`, `cal 9 1752` (anything unusual?), `date`, `hostname`,
`arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`,
`last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`,
`history | tail`.

```{bash}
#| eval: false
cal
cal 2024
cal 9 1752
date
hostname
arch
uname -a
uptime
who am i
who
w
id
last | head
echo {con,pre}{sent,fer}{s,ed}
time sleep 5
history | tail
```

cal: displays a calendar for the current month 

cal 2024: displays a
calendar for the year 2024 

cal 9 1752: displays a calendar for the month
of September in the year 1752 

date: displays the current date and time

hostname: displays the name of the current host 

arch: displays the
architecture of the current system 

uname -a: displays detailed
information about the current system 

uptime: displays the current time,
how long the system has been running, and the number of users currently
logged in 

who am i: displays the current user's login name who: displays
a list of all users currently logged in 

w: displays a list of all users
currently logged in, along with additional information such as the time
they logged in and the current process they are running 

id: displays the
current user's UID and GID 

last \| head: displays a list of the last
users to log in, along with the time they logged in and the terminal
they used 

echo {con,pre}{sent,fer}{s,ed}: displays the words "consents",
"confered", "presents", and "preferred" on separate lines

time sleep 5: displays the amount of time it takes to run the "sleep 5" command
history \| tail: displays the last 10 commands entered into the shell

## Q6. Book

1.  Git clone the repository
    <https://github.com/christophergandrud/Rep-Res-Book> for the book
    *Reproducible Research with R and RStudio* to your local machine.
    terminal commands:

```{bash}
#| eval: false
git clone https://github.com/christophergandrud/Rep-Res-Book ~/git_book
```

2.  Open the project by clicking `rep-res-3rd-edition.Rproj` and compile
    the book by clicking `Build Book` in the `Build` panel of RStudio.
    (Hint: I was able to build `git_book` and `epub_book` but not
    `pdf_book`.)

The point of this exercise is (1) to get the book for free and (2) to
see an example how a complicated project such as a book can be organized
in a reproducible way.

For grading purpose, include a screenshot of Section 4.1.5 of the book
here.

![](./screenshot hw1_Q6.png)
[Screenshot](https://drive.google.com/file/d/1PYwz0_vB45XhIs1EQDhSh5VXOgeD4m-D/view?usp=sharing)
